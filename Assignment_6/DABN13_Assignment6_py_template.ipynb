{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b1cb77-5344-418c-94b3-7bacb800c746",
   "metadata": {},
   "source": [
    "# DABN13 - Assignment 6\n",
    "\n",
    "## Preamble: Data\n",
    "In this lab we are using a dataset on beer purchases. Our goal is to predict if light beer purchased in the US is BUD light. To achieve this goal, we will use the information provided by the following socioeconomic characteristics:\n",
    "* market           - where the beer is bought\n",
    "* buyertype        - who is the buyer () \n",
    "* income           - ranges of income\n",
    "* childrenUnder6   - does the buyer have children under 6 years old\n",
    "* children6to17    - does the buyer have children between 6 and 17\n",
    "* age              - bracketed age groups\n",
    "* employment       - fully employed, partially employed, no employment.\n",
    "* degree           - level of occupation\n",
    "* occuptation      - which sector you are employed in\n",
    "* ethnic           - white, asian, hispanic, black or other\n",
    "* microwave        - own a microwave\n",
    "* dishwasher       - own a dishwasher\n",
    "* tvcable          - what type cable tv subscription you have\n",
    "* singlefamilyhome - are you in a single family home\n",
    "* npeople          - number of people you live with 1,2,3,4, +5\n",
    "\n",
    "First, we load the dataset and create an output variable that indicates purchases of Bud Light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620cb558-0655-4ff6-80d8-51cc89e3c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73115, 24)\n",
      "(73115, 123)\n",
      "(73115,)\n",
      "   household   upc_description  quantity beer_brand  beer_spend  beer_floz  \\\n",
      "0    2000946  BUD LT BR CN 12P         1  BUD LIGHT        8.14      144.0   \n",
      "1    2003036  BUD LT BR CN 24P         1  BUD LIGHT       17.48      288.0   \n",
      "2    2003036  BUD LT BR CN 24P         2  BUD LIGHT       33.92      576.0   \n",
      "3    2003036  BUD LT BR CN 30P         2  BUD LIGHT       34.74      720.0   \n",
      "4    2003036  BUD LT BR CN 36P         2  BUD LIGHT       42.96      864.0   \n",
      "\n",
      "   price_floz container_descr  promotion          market  ...  age employment  \\\n",
      "0    0.056528             CAN      False  RURAL ILLINOIS  ...  50+       none   \n",
      "1    0.060694             CAN      False         ATLANTA  ...  50+       full   \n",
      "2    0.058889             CAN      False         ATLANTA  ...  50+       full   \n",
      "3    0.048250             CAN      False         ATLANTA  ...  50+       full   \n",
      "4    0.049722             CAN      False         ATLANTA  ...  50+       full   \n",
      "\n",
      "    degree              occupation ethnic microwave dishwasher  tvcable  \\\n",
      "0     Grad    none/retired/student  white      True       True  premium   \n",
      "1  College  clerical/sales/service  white      True       True    basic   \n",
      "2  College  clerical/sales/service  white      True       True    basic   \n",
      "3  College  clerical/sales/service  white      True       True    basic   \n",
      "4  College  clerical/sales/service  white      True       True    basic   \n",
      "\n",
      "  singlefamilyhome  npeople  \n",
      "0            False        1  \n",
      "1             True        2  \n",
      "2             True        2  \n",
      "3             True        2  \n",
      "4             True        2  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "       household       upc_description  quantity     beer_brand  beer_spend  \\\n",
      "73110    9062536  NATURAL LT BR CN 30P         1  NATURAL LIGHT       16.59   \n",
      "73111    9062536  NATURAL LT BR CN 30P         1  NATURAL LIGHT       16.59   \n",
      "73112    9103985  NATURAL LT BR CN 30P         1  NATURAL LIGHT       13.88   \n",
      "73113    9158319  NATURAL LT BR CN 24P         1  NATURAL LIGHT        9.98   \n",
      "73114    9164033  NATURAL LT BR CN 30P         1  NATURAL LIGHT       12.98   \n",
      "\n",
      "       beer_floz  price_floz container_descr  promotion          market  ...  \\\n",
      "73110      360.0    0.046083             CAN      False           TAMPA  ...   \n",
      "73111      360.0    0.046083             CAN      False           TAMPA  ...   \n",
      "73112      360.0    0.038556             CAN      False         DETROIT  ...   \n",
      "73113      288.0    0.034653             CAN      False  RURAL VIRGINIA  ...   \n",
      "73114      360.0    0.036056             CAN      False      SACRAMENTO  ...   \n",
      "\n",
      "       age employment   degree              occupation    ethnic microwave  \\\n",
      "73110  50+       part       HS  clerical/sales/service     white      True   \n",
      "73111  50+       part       HS  clerical/sales/service     white      True   \n",
      "73112  50+       full       HS                    prof     white      True   \n",
      "73113  50+       none       HS    none/retired/student     black      True   \n",
      "73114  50+       full  College                    prof  hispanic      True   \n",
      "\n",
      "      dishwasher  tvcable singlefamilyhome  npeople  \n",
      "73110      False     none             True        2  \n",
      "73111      False     none             True        2  \n",
      "73112       True     none             True        2  \n",
      "73113       True  premium             True        2  \n",
      "73114       True    basic             True    5plus  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "np.random.seed(2023)\n",
    "tf.random.set_seed(2023)\n",
    "random.seed(2023)\n",
    "\n",
    "\n",
    "# os.chdir(\"??\") Change working directory if needed \n",
    "\n",
    "lb    = pd.read_csv(\"LightBeer2.csv\")\n",
    "y     = np.zeros(shape=lb.shape[0])\n",
    "y[lb['beer_brand'] == \"BUD LIGHT\"]     = 1\n",
    "demog = lb.iloc[:,9:]\n",
    "demog = pd.get_dummies(demog, drop_first=True)\n",
    "\n",
    "# inspect the data\n",
    "print(lb.shape)\n",
    "print(demog.shape)\n",
    "print(y.shape)\n",
    "# inspect first 5 and last 5\n",
    "print(lb.head())\n",
    "print(lb.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88174fd7-d779-4207-a30e-224c89bdcbc9",
   "metadata": {},
   "source": [
    "We also split the data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c287b-7069-426c-b3c1-15857ff123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(demog, y, train_size=0.75, shuffle=False)\n",
    "\n",
    "stdz_X = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = stdz_X.transform(X_train)\n",
    "X_test  = stdz_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25983d48-57e5-4342-9935-16676fd3a106",
   "metadata": {},
   "source": [
    "## Part 1: Specifying and training neural networks\n",
    "We will now start building a neural network to predict the purchase of Bud Light."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c7cab-178e-4fee-b942-8ab68a140e23",
   "metadata": {},
   "source": [
    "### Task 1a) \n",
    "We start with specifying the architecture of our very first and very small neural net `model1`.\n",
    "Add three layers to `model1`, two hidden layers with $30$ and $15$ hidden units, respectively, and an output layer.\n",
    "For the two hidden layers you should use the ReLU activation function. Additionally, choose a suitable activation for the output layer, given that we have a classification problem. See [the Keras documentation](https://keras.io/api/layers/activations/) for activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9388d-cbd6-4d10-90ff-2c3d974a8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Initialize a first model\n",
    "model1 = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model1.add(layers.Dense(30, input_dim=X_train.shape[1], activation='ReLU'))\n",
    "model1.add(layers.Dense(15, activation = 'ReLU'))\n",
    "model1.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bcd214-22bf-42fa-a973-2c27f0643431",
   "metadata": {},
   "source": [
    "### Task 1b) \n",
    "\n",
    "Next, we compile our model specification. From [https://keras.io/api/losses/probabilistic_losses/](losses) select a suitable loss function for our classification problem. As optimization algorithm use *Adam* with learning rate $0.00003$. Lastly, use `accuracy` as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88ddd5-3e85-4238-96a3-81b914f4fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.00003), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2904463-9a53-4ea3-b175-adfc9ff0f599",
   "metadata": {},
   "source": [
    "### Task 1c)\n",
    "Now train the model using $250$ epochs, a batch_size of $2^8$, and use $25\\%$ of the data for validation.\n",
    "Use the string variable `loss_valloss_difference_1c` to describe and explain the observed difference between validation loss and training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00f52b-92c7-4100-bfe0-05cdd6f0fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_train, y_train, epochs=250, batch_size=2**8, validation_split=0.25)\n",
    "\n",
    "loss_valloss_difference_1c = \"Training loss indicates how well the model is fitting the training data, whereas the validation loss indicates how well the model is generalizing to new data. At some point the validation loss actually increases, which indicates that the model is overfitting the training data. Ideally we would want to use less epochs so that the model does not overfit the training data, because this in turn also affects the accuracy of the model.  \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74189128-f787-4b8c-8c96-6b782065dad7",
   "metadata": {},
   "source": [
    "### Task 1d)\n",
    "In Lecture 9 we used early stopping to avoid overfitting. Apply this here, with `patience` argument set to 20, a new model `model1b` which otherwise should have a setup identical to `model1`. In which epoch did the model training procedure stop? Figure this out by counting the number of elements in `model1b_fit.history['loss']` and write your answer into the string variable `when_earlystop_1d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13f2cb-b29b-4288-9b8d-e69f331faff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define architecture here\n",
    "model1b = keras.Sequential()\n",
    "model1b.add(layers.Dense(30, input_dim=X_train.shape[1], activation='ReLU'))\n",
    "model1b.add(layers.Dense(15, activation = 'ReLU'))\n",
    "model1b.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model here \n",
    "model1b.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.00003), metrics=['accuracy'])\n",
    "\n",
    "# Fit model here\n",
    "model1b_fit = model1b.fit(X_train, y_train, epochs=250, batch_size=2**8, validation_split=0.25, callbacks=[EarlyStopping(patience=20)])\n",
    "\n",
    "when_earlystop_1d = f\"Early stopping is used to stop the training of the model when a monitored\\nmetric has stopped improving. In this case the monitored\\nmetric is the validation loss. The patience parameter\\nis used to specify how many epochs the model should\\nwait before stopping the training. In this case\\nthe model stopped training after {len(model1b_fit.epoch)} epochs.\"\n",
    "\n",
    "print(when_earlystop_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9a95a-7770-493e-9596-52d9ee9aeefc",
   "metadata": {},
   "source": [
    "### Task 1e)\n",
    "Even though we haven't finished training our neural net, let us use the `evaluate()` function to measure the predictive performance of `model1b` on the test data. Save the result as `res_model1`. \n",
    "\n",
    "What is the accuracy of the model for validation training data and test data, respectively? What is the difference in accuracy? Save your answer in the string variable `difference_in_accuracy_1e`.\n",
    "*Hint:* the training validation accuracy can be extracted from `model1b_fit`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb727607-775d-44a3-a437-de1d7db42459",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model1b = model1b.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "print(res_model1b)\n",
    "\n",
    "difference_in_accuracy_1e = f\"The accuracy for the validation training data is\\n{model1b_fit.history['val_accuracy'][-1]} and the test data accuracy is {res_model1b[1]} and he difference between\\nthe model for validation training data accuracy and test data accuracy is\\n{abs(model1b_fit.history['val_accuracy'][-1]) - res_model1b[1]}\"\n",
    "\n",
    "print(difference_in_accuracy_1e)\n",
    "\n",
    "# print the accuracy of the model for validation training data and test data\n",
    "#print(f\"Accuracy for validation training data: {model1b_fit.history['accuracy'][-1]}\")\n",
    "#print(f\"Accuracy for test data: {res_model1b[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef98a6a-2952-4733-a42e-45a44cdcc7f9",
   "metadata": {},
   "source": [
    "### Task 1f)\n",
    "Now we use the `confusion_matrix()` function from the `metrics` module of scikit-learn to disaggregate model performance to class-specific performance. First, get class predictions on the test data using `predict()`. Save these as `prob_model1`. \n",
    "Second, use `confusion_matrix()` to get a confusion matrix and save it as `CM_model1`. Third, calculate true positive rate and false positive rate and save them as `TPR_1f` and `FPR_1f`. \n",
    "Do your results on TPR and FPR suggest that prediction accuracy is approximately equal in both categories? Write your (specific!) answer into the string variable `categorywise_accuracy_1f`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d16957-1fcb-48b0-891c-9b778149090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "prob_model1 = model1b.predict(X_test)\n",
    "CM_model1   = confusion_matrix(y_test, prob_model1 > 0.5)\n",
    "\n",
    "TN = CM_model1[0,0]\n",
    "TP = CM_model1[1,1]\n",
    "FN = CM_model1[1,0]\n",
    "FP = CM_model1[0,1]\n",
    "\n",
    "\n",
    "TPR_1f = TP/(TP + FN)\n",
    "FPR_1f = FP/(FP + TN)\n",
    "\n",
    "print(CM_model1)\n",
    "print(TPR_1f)\n",
    "print(FPR_1f)\n",
    "\n",
    "categorywise_accuracy_1f = \"The model is much better at predicting true negatives, where approximately 80 percent of true negatives are predicted correctly, whereas true positive is only approximately 47 percent correctly predicted. The model is also better at predicting false negatives, where approximately 53 percent of false negatives are predicted correctly, whereas false positives is only approximately 20 percent correctly predicted. One could consider decreasing the decision boundary to increase the true positive rate, but this would in turn increase the false positive rate. Which would be worse than the current situation, because the model is better at predicting true negatives than false positives. \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b6fa2-89ad-4d87-bc6e-5031b13b1f7b",
   "metadata": {},
   "source": [
    "### Task 1g)\n",
    "\n",
    "In the lectures we have utilized explicit regularization to avoid overfitting. Here we will use $\\ell_2$ regularization to update the weights. Create the architecture of a new neural net `model2` which is identical to that of `model1b` except for $l_2$ regularization with regularization factor `l2_pen` in the two hidden layers.  \n",
    "\n",
    "Then compile and fit this regularized model with the same parameters as in Task 1d. Save the trained neural net as `model2_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505b575-e5e1-4d4d-b42b-70960a1222d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "l2_pen = 0.005\n",
    "\n",
    "# 1.\n",
    "model2 = keras.Sequential()\n",
    "model2.add(layers.Dense(30, input_dim = X_train.shape[1], activation = 'ReLU', kernel_regularizer = l2(l2_pen)))\n",
    "model2.add(layers.Dense(15, activation = 'ReLU', kernel_regularizer = l2(l2_pen)))\n",
    "model2.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# 2.\n",
    "model2.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 0.00003), metrics = ['accuracy'])\n",
    "model2.fit(X_train, y_train, epochs = 250, batch_size = 2**8, validation_split = 0.25, callbacks=[EarlyStopping(patience=20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a8d24-9b08-48fe-b120-ca68106406fb",
   "metadata": {},
   "source": [
    "### Task 1h)\n",
    "In Task 1e) we compared the prediction accuracy on test and training sets. However, this is bad measure when the data is not well balanced (in terms of the observed output categories). Instead, one can use the cross entropy for the binomial distribution (minus the average log likelihood of the model). In fact, we chose this function as loss function for model training when we compiled `model1` and `model2`.\n",
    "\n",
    "To compare the test error of `model2` to that of `model1b` we don't want to use `loss` from `evaluate` since this includes the $\\ell_2$ penalty.  In the library `MLmetrics` the function `log_loss()` computes the cross entropy for the binomial distribution without penalty term. \n",
    "\n",
    "First, get predicted output probabilities on test data from `model2` and save them as `prob_model2`.\n",
    "Second, use `log_loss()` from the metrics module in scikit-learn to compute the cross-entropy loss for `model2` on the test data and save it as `logloss_model2`. \n",
    "Third, use the string variable `performance_comparison_1h` to describe how the accuracy on test data differs between `model1b` and `model2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a39ea-f599-4f1d-9ca0-4e54aa598cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 1. \n",
    "prob_model2    = model2.predict(X_test)\n",
    "\n",
    "# 2.\n",
    "logloss_model2 = log_loss(y_test, prob_model2)\n",
    "print(logloss_model2)\n",
    "\n",
    "# 3.\n",
    "accu_model2     = model2.evaluate(X_test, y_test, verbose = 0)[1]\n",
    "performance_comparison_1h = f\"From the log loss we can that the model is performing even better when adding a penalty,\\nquite significantly actually, the log loss is {logloss_model2:.6f} compared to {res_model1b[0]:.6f}\\nfor model 1b. The accuracy achieved is {accu_model2:.6f} with\\na penalty and {res_model1b[1]:.6f} without a penalty. The difference between loss of the two models\\nis {abs(logloss_model2 - res_model1b[0]):.6f} and the difference between the accuracy of the two models is\\n{abs(accu_model2 - res_model1b[1]):.6f}. One could also imagine that if even more features were added to the model,\\nthe penalty term would perform even better.\"\n",
    "print(performance_comparison_1h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d8bf1-f86e-4b0c-9cc6-bdd9f1d964c4",
   "metadata": {},
   "source": [
    "## Part 2: Tuning neural nets with caret\n",
    "\n",
    "Keras provides functions that allow the use of scikit-learn for model tuning. Using this functionality requires relatively little effort and in this part we are going to practice the individual steps of model tuning with `sklearn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac151a-c3c3-44e8-8adb-a8a3cedd6d95",
   "metadata": {},
   "source": [
    "### Task 2a)\n",
    "First, we need to define the architecture of the neural net that we tune and to compile the model. This needs to be done inside a function. The arguments of this function are the tuning parameters whose candidate values we want to feed into the function one by one.\n",
    "\n",
    "In this task, we work with the architecture defined for `model2` in Task 1g. The only parameter that we want to tune is the regularization parameter for $\\ell_2$ penalization inside the hidden units.\n",
    "\n",
    "Now create a function `modelbuild_2a` which has one argument `l2_pen`. In this function, specify the architecture of a Keras model `model`, identical to that of `model2` and with $\\ell_2$-penalty set to `ell_2`. Compile the model with the same settings as in Task 1g and return it as function output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfec657-d581-4b0c-b751-114dc1496386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelbuild_2a(l2_pen):\n",
    "    ell_2 = l2_pen\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(30, input_dim=X_train.shape[1], activation='ReLU', kernel_regularizer=l2(ell_2)))\n",
    "    model.add(layers.Dense(15, activation='ReLU', kernel_regularizer=l2(ell_2)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.00003), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64078933-0ccc-4f9e-abb6-e26520bd8760",
   "metadata": {},
   "source": [
    "### Task 2b)\n",
    "In order to make the function `modelbuild_2a` compatible with `sklearn`, we need to call it inside the `KerasClassifier()` function from the `wrappers` module of `scikit-learn`. As additional arguments, provide all arguments that you used when fitting `model2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027797af-2ee2-4566-8c67-ef98b0f40f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "model2_sklearn_spec = KerasClassifier(build_fn = modelbuild_2a, l2_pen = 0.0, epochs = 250, batch_size = 2**8, validation_split = 0.25, callbacks=[EarlyStopping(patience=20)], verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3cce66-a557-4597-80dc-bb1ff84b4f1e",
   "metadata": {},
   "source": [
    "### Task 2c)\n",
    "Next, define a parameter grid `tune_grid_2c`. This must be a dictionary object. Ensure that the only object within `tune_grid_2c` is called `l2_pen`. Its values should be zero as well as $10^{r}$ for a grid of eleven $r$-values from $-4$ and $-1$ at equal distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63925c0d-6abd-49e6-bfad-5adc320ce894",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid_2c = {'l2_pen': np.insert(np.logspace(-4, -1, 11), 0, 0).tolist()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a978345-6081-478b-9549-771d300a1992",
   "metadata": {},
   "source": [
    "### Task 2d)\n",
    "Now, we can tune our model. That's computationally quite costly, so we will use merely a fraction of the available training data. The inputs and outputs for this task are given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e12d402-63b4-420b-a4b0-8c6f2830fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small,_ , y_train_small, _ = train_test_split(X_train, y_train, train_size=0.3, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69847933-232b-499f-847a-04255215d8cd",
   "metadata": {},
   "source": [
    "Do the following:\n",
    "\n",
    "1. Use `Kfold()` from the model selection module in scikit-learn to define a random partition of the training data into five folds. Use $5$ as your random seed. Save this partition as `cv_splits_2d`\n",
    "2. Call `GridSearchCV()` and use the wrapper function from Task 2b, the parameter grid from Task 2c as well as `cv_splits_2d` as arguments\n",
    "3. Apply the `fit()`-method to `GridSearchCV` and use `X_train_small` and `y_train_small` as inputs and outputs, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8746fa6-0cd3-469c-afb2-7278ee02ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (KFold, GridSearchCV)\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 1.\n",
    "cv_splits_2d = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "# 2.\n",
    "NN_tune_2d = GridSearchCV(estimator = model2_sklearn_spec, param_grid = tune_grid_2c, cv = cv_splits_2d, n_jobs = 1)\n",
    "\n",
    "# 3.\n",
    "NN_tune_2d.fit(X_train_small, y_train_small)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Cross validation finished in {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c16a15-f9d0-4d38-896a-627e4d5dde75",
   "metadata": {},
   "source": [
    "### Task 2e)\n",
    "By default, GridSearchCV saves the trained model with the best tuning parameter values as as object `best_estimator_` inside `NN_tune_2d`. However, in our case this model is a KerasClassifier object. We cannot use such an object for making predictions on test data. \n",
    "\n",
    "Still, the KerasClassifier object contains the trained model in the typical Keras format as object `model`. Extract this object-inside-the-object-inside-the-object and save it as `model3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ec904-ce98-4907-b3fa-cc54b1a43cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6448b-ac63-4129-9236-6dcb23bcf1dd",
   "metadata": {},
   "source": [
    "## Part 3: Saving, loading and retraining neural nets \n",
    "\n",
    "### Task 3a)\n",
    "\n",
    "Training and tuning neural nets can take a lot of time. Therefore, it is possible to save entire fitted models to disk and to import them at a later point in time. Apply the `save()`-method to your most recent `model3` in order to save it as *DABN13_asst6_saved_model3* in your working directory.\n",
    "\n",
    "Ensure that the model is saved in TensorFlow SavedModel format.\n",
    "\n",
    "Additionally, use the file explorer in your operating system to look how exactly the model was saved on your hard drive. Describe this shortly in the string_variable `saved_model_3a`\n",
    "\n",
    "*Note:* Functions for saving and loading models are very nicely described in the [keras documentation](https://keras.io/api/saving/model_saving_and_loading/#save-method)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e1779-a59c-4153-9c89-39d3be986fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "??\n",
    "\n",
    "saved_model_3a = \"??\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424edf9-37e1-4b9e-9c91-4836c6367709",
   "metadata": {},
   "source": [
    "### Task 3b)\n",
    "\n",
    "Now, use the `load_model` function in the `models` module of Keras to load your saved model into your python session again. Save this model as `model4`.\n",
    "\n",
    "*Note:* The possibility to load a previously saved model from your hard disk is useful for more than just your own models. It even allows you to load pretrained models for specific purposes from the TensorFlow Hub or from Hugging Face. These models could then directly be used for prediction or fine-tuned on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f89a6c-9730-4dbd-950f-2d5b5f2f0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model4 = ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83385071-18a5-4ca3-906e-895fdeb9c692",
   "metadata": {},
   "source": [
    "### Task 3c)\n",
    "\n",
    "When we tuned our most recent neural net, we did this on a relatively small fraction of the training data to reduce the computational cost. This was also the data used to train the best model that we extracted from `NN_tune_2d`.\n",
    "Now that we have chosen an optimal tuning parameter, it makes sense to retrain the `model4` on the entire training data `X_train` and `y_train`. Do this by applying the `fit()` method to `model4`. As previously, training should be done for 250 epochs, unless early stopping with a patience of 20 epochs kicks in. Minibatches of $2^8$ data points should be used. Given the large amount of data, hold only 10% of the data aside for monitoring validation loss.\n",
    "\n",
    "Once you retrained your model, obtain predicted class probabilities and save them as `prob_model4`. Then, get the log loss `logloss_model4` on the test data.\n",
    "\n",
    "Finally, to what extend did model tuning and retraining change test set accuracy relative to that of `model2`? Comment on this in the string variable `performance_comparison_3c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f945e31-63c3-48ef-a5e2-54e7b36cdddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "??\n",
    "\n",
    "# 2.\n",
    "prob_model4    = ??\n",
    "logloss_model4 = ??\n",
    "print(logloss_model4)\n",
    "\n",
    "# 3.\n",
    "performance_comparison_3c = \"??\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7766e3e-925d-434b-a546-35b8a77fa177",
   "metadata": {},
   "source": [
    "## Part 4: Manual predictions from a trained neural net\n",
    "\n",
    "In this part we will build predictions *manually* by extracting weights from the trained  `model2` and by constructing the transformations in the layers of the neural net ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3b6b3-6107-41d3-8bd4-09cc1c393791",
   "metadata": {},
   "source": [
    "### Task 4a)\n",
    "\n",
    "Start this task by creating your own ReLU activation function. Save it as `ReLU`. Then, write your own sigmoid function for the output layer transformation. Save it as  `sigmoid`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755df496-d94c-48b7-8a0d-d406e94d6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation function\n",
    "??\n",
    "\n",
    "# Sigmoid activation function\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d8157-ef24-4994-a4bd-34827db28d8e",
   "metadata": {},
   "source": [
    "### Task 4b)\n",
    "In the slides for lecture 8 we discussed how units in the different layers of a neural net look like. Now we are going to use the equations both hidden units and output unit to construct output predictions for the $n_{test}$ data points in `X_test`. Please do the following:\n",
    "\n",
    "1. Apply the `get_weights()` method on `model2` to obtain a list object which stores the weights and biases of the learned model. Save it as `weight_and_bias_4b`.\n",
    "2. Extract the objects inside `weight_and_bias_4b` into the objects for $\\mathbf{b}_1,\\mathbf{W}_1, \\mathbf{b}_2, \\mathbf{W}_2,\\mathbf{b}_3, \\mathbf{W}_3$ defined in the code chunk below.\n",
    "3. Construct the linear term of the first layer hidden units and save these linear terms as a $30 \\times n_{train}$ vector `Z_1`.\n",
    "4. Construct the $15 \\times n_{train}$ vector `Z_2` of linear terms for the second layer hidden units. Then, obtain the linear term of the output unit and save it as `Z_3`.\n",
    "5. Put `Z_3` into the output layer activation function in order to get predictions for the probability of a Bud Light purchase. Save this as $n_{train} \\times 1$ vector `pred_own_2b`. \n",
    "\n",
    "*Hint*: You can use `dim()` to check the dimension of matrices and `length()` to check that of vectors. Additionally, to ensure that you got the correct result for `prob_model2_own_4b` you can compare it with the output of `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50523588-05be-4174-b294-392f96cd8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "weight_and_bias_4b = ??\n",
    "\n",
    "# 2.\n",
    "WW_1 = ??\n",
    "bb_1 = ??\n",
    "WW_2 = ??\n",
    "bb_2 = ??\n",
    "WW_3 = ??\n",
    "bb_3 = ??\n",
    "\n",
    "# 3.\n",
    "Z_1 = ??\n",
    "\n",
    "# 4.\n",
    "Z_2 = ??\n",
    "Z_3 = ??\n",
    "\n",
    "# Apply sigmoid activation to Z_3\n",
    "prob_model2_own_4b = ??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
