{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4963fb3-8560-4716-b52e-086415d6ff73",
   "metadata": {},
   "source": [
    "# DABN13 - Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f552c6-e6b9-4a60-b603-3bec06df2c6e",
   "metadata": {},
   "source": [
    "## Preamble: Predicting competitor airfares on new routes\n",
    "\n",
    "Air carriers regularly update their destination network and a necessary condition for adding a new flight connection to the existing network is that flights on this route are profitable. In addition to costs, profitability is determined by the price at which competitors could cater to the demand for flight transportation between two locations. A data-driven way of determining this would be on the basis of a supervised learning algorithm that has been trained on the fares for existing flight connections and which leverages information about route-specific characteristics. The dataset that we are using in this lab contains such information for more than 600 flight connections between different American cities. More specifically, we have information on the number of required stops, the market concentration on a particular route, Holiday destination status and a number of other characteristics that are detailed on [p.7 in the `mlba` library documentation](https://github.com/gedeck/mlba/blob/main/mlba_2.0.0.pdf). In the following, we will train and tune different supervised learning models that predict the average fare for a flight.\n",
    "\n",
    "\n",
    "Before conducting the first part of this assignment, let's load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767b68e-054f-4e26-866a-e3275b861ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "Airfares = pd.read_csv(\"Airfares.csv.gz\") # Adjust file path if necessary\n",
    "Airfares = Airfares.drop(columns=[\"S_CODE\", \"S_CITY\", \"E_CODE\", \"E_CITY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab976f-2e08-4c94-81d0-dbac1f8a5641",
   "metadata": {},
   "source": [
    "## Part one: Ridge regression with scikit-learn\n",
    "Ridge regression is supported in the `linear_models` module of scikit-learn. However, instead of using the `Ridge()`-function in this module, we are going to work with `ElasticNet()` because this function leads to ridge regression and the lasso as special cases. \n",
    "\n",
    "### Task 1a)\n",
    "`sklearn` requires us to provide output and inputs separately as data frames containing numerical variables that can be directly put into a cost minimization problem. Provide that by conducting the following steps:\n",
    "\n",
    "1. Save *all* predictors in `Airfares` as a Pandas dataframe `X_1a`. Then, use the `get_dummies()` function in Pandas to turn categorical variables into category dummies. Ensure that the first category of every categorical variable is dropped.\n",
    "2. Save the output variable *FARE* as pandas series `y_1a`\n",
    "3. Use the  `train_test_split()` function in the model selection module of `sklearn` to split `X_1a` (`y_1a`) into training data `X_train_1a` (`y_train_1a`) and test data `X_test_1a` (`y_test_1a`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32ebbc-6edd-442c-85a5-fcf4f6b5c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "X_1a = ??\n",
    "X_1a = pd.get_dummies(??)\n",
    "\n",
    "# 2. \n",
    "y_1a = ??\n",
    "\n",
    "\n",
    "# 3.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51c0ed-c761-4ad8-8b33-5c2131fc48a2",
   "metadata": {},
   "source": [
    "### Task 1b)\n",
    "With a little effort, we can use `sklearn` to plot the relation between learned model coefficients and the regularization parameter.\n",
    "Unlike other estimator functions in `sklearn`, we the coefficient path cannot be obtained by simply fitting a specified pipeline. We need to conduct all steps in that potential pipeline manually. \n",
    "\n",
    "1. First, we manually do more data transformations. We want to expand the set of input variables by adding interactions of all original inputs to the data set. The function `PolynomialFeatures()` does that for us. Use this function to specify a transformation `poly2_spec_1b` which adds interactions between any two input variables to the data. Do not add squared terms and no constant neither.\n",
    "2. We can even use the `Pipeline()` function without an estimator, e.g. do specify a sequence of transformations. Create such a pipeline `X_transform_pipe_1b`. Its should contain `poly2_spec_1b` as its first step and standardization of all variables in the dataset (via `StandardScalar()` as its second step)\n",
    "3. Use the `fit_transform()`-method on `X_transform_pipe_1b` to transform `X_train_1a` and save the result as `X_train_transformed_1b`\n",
    "4. Use the `enet_path()` function to learn the sequence of ridge regression parameters for the sequence of regularization parameter values `lambdas_1b` that I defined below. You will need to specify your model inputs and output, as well as the choice of `l1_ratio` which results in ridge regression. Save the result as `ridgepath_1b`. Then, run the provided code for plotting the coefficient path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484d493-40f7-46a3-8ec7-a010648ad0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (StandardScaler, PolynomialFeatures)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import enet_path\n",
    "\n",
    "# 1.\n",
    "poly2_spec_1b    = ??\n",
    "\n",
    "# 2.\n",
    "X_transform_pipe_1b = ??\n",
    "\n",
    "# 3.\n",
    "X_train_transformed_1b = ??\n",
    "\n",
    "# 4.\n",
    "lambdas_1b = (np.logspace(7, 0, 100)/(y_train_1a.std(ddof=1)*2 * y_train_1a.shape[0]))\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    ridgepath_1b    = enet_path(??)\n",
    "\n",
    "\n",
    "# Run the lines below for a plot of the coefficient path\n",
    "ax = plt.gca()\n",
    "for i in range(ridgepath_1b[1].shape[0]):\n",
    "    plt.plot(ridgepath_1b[0]*y_train_1a.shape[0]*2, ridgepath_1b[1][i])\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"learned coefficients\")\n",
    "plt.title(\"Ridge coefficient path\")\n",
    "plt.axis(\"tight\") \n",
    "plt.grid(True)   \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4fe36-5e39-4290-8598-443281955984",
   "metadata": {},
   "source": [
    "### Task 1c)\n",
    "Now that we have inspected the coefficient path for ridge regression, we want to find an optimal tuning parameter value via K-fold cross-validation. This works almost exactly as in Assignment 3.\n",
    "\n",
    "1. Specify a pipeline that contains the two transformations that we already specified in `X_transform_pipe_1b` as well as a ridge regression specification (use `Ridge()`). Save the specified pipeline as `ridge_pipe_1c`. \n",
    "\n",
    "2. Put the set of tuning parameter candidates `lambdas_1c` below into a dictionary object `tune_grid_1c` that `GridSearchCV()` can handle when estimation function is the pipeline `ridge_pipe_1c`.\n",
    "\n",
    "3. Use the `KFold()`-function to specify a **random** partition into five folds. Set the `random_state` to 5 for the sake of replicability.\n",
    "\n",
    "4. Do 5-fold cross-validation to determine the optimal regularization parameter value among the candidates in `lamndas_1b` by calling the `GridSearchCV()`-function. Use the pipeline and the split specified in the previous two steps. Measure prediction performance with (negative) mean squared error. Save the resulting object as `ridge_tune_1c`.\n",
    "5. Save the `cv_results_` object in `ridge_tune_1c` as `ridge_cv_out_1c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985bb01-4891-48a5-84b1-bbc230e9be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import (KFold, GridSearchCV)\n",
    "\n",
    "# 1.\n",
    "ridge_pipe_1c  = Pipeline(steps = [??])\n",
    "\n",
    "# 2.\n",
    "lambdas_1c = np.logspace(7, 0, 100)/(y_train_1a.std(ddof=1))\n",
    "tune_grid_1c = ??\n",
    "\n",
    "# 3.\n",
    "cv_splits_1c = ??\n",
    "\n",
    "# 4.\n",
    "ridge_tune_1c   = GridSearchCV(??)\n",
    "ridge_tune_1c.fit(??)\n",
    "\n",
    "# 5.\n",
    "ridge_cv_out_1c = ??\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77945f-3600-4711-b068-95eb45dd8a44",
   "metadata": {},
   "source": [
    "### Task 1d) \n",
    "In the code block below, you will find a function `elnet_cvplot_1d` which plots cross-validation errors together with bands at a distance of one standard deviation. It also indicates the position of the tuning parameter value with minimal cross-validation error and of the value that would be chosen according to the one-S.E. rule. The function is almost complete - you only need to do the following:\n",
    "\n",
    "1. Ensure that the object `min_error_index` contains the index of the tuning parameter leading to the smallest cross-validation error. `argmin()` in NumPy does that for you.\n",
    "2. Allocate to `one_se_rule_index` the index of the tuning parameter value that would be chosen according to the one-standard error rule. You could do that by using the NumPy function `where()` to ask which cross-validation errors are smaller than the minimum cross-validation error plus one standard error. The first element in the resulting array should contain the index that you are looking for.\n",
    "3. Create a dictionary object `best_lams` with elements \"lambda_min\" and \"lambda_1se\" which contain the values of the tuning parameter suggested by minimum cross-validation error and the one-S.E. rule, respectively. Tell your python function to return `best_lams`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4958f-d0fd-4661-8c88-592e0b86fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elnet_cvplot_1d(lambdas, cv_errors, std_errors):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - lambdas: Array of tuning parameter values.\n",
    "    - cv_errors: Array of cross-validation errors corresponding to tuning parameters.\n",
    "    - std_errors: Array of standard errors of cross-validation errors.\n",
    "    \"\"\"\n",
    "    # Do not change anything in the following six lines\n",
    "    sort_idx   = np.argsort(lambdas)\n",
    "    lambdas    = lambdas[sort_idx]\n",
    "    cv_errors  = cv_errors[sort_idx]\n",
    "    std_errors = std_errors[sort_idx]\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(lambdas, cv_errors, linestyle='-', color='blue', label='CV Error')\n",
    "    \n",
    "    upper_band = np.array(cv_errors) + np.array(std_errors)\n",
    "    lower_band = np.array(cv_errors) - np.array(std_errors)\n",
    "    plt.fill_between(lambdas, lower_band, upper_band, color='gray', alpha=0.6, label='±1 SE')\n",
    "\n",
    "    # 1.\n",
    "    min_error_index = ??\n",
    "    plt.axvline(x=lambdas[min_error_index], color='gray', linestyle='--', label='Min Error')\n",
    "\n",
    "    # 2.\n",
    "    one_se_rule_index = ??\n",
    "    plt.axvline(x=lambdas[one_se_rule_index], color='gray', linestyle=':', label='1SE rule')\n",
    "    \n",
    "    # Do not change the seven lines below\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Regularization parameter values')\n",
    "    plt.ylabel('Cross-Validation error')\n",
    "    plt.title('Cross-Validation Error with One Standard Error Bands')\n",
    "    plt.legend()\n",
    "    plt.grid(True)   \n",
    "    plt.show()\n",
    "\n",
    "    # 3.\n",
    "    best_lams=??\n",
    "    ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869a2c9-06be-47c2-97cb-2e2ded30a72b",
   "metadata": {},
   "source": [
    "### Task 1e) \n",
    "Call the function `elnet_cvplot_1d` in order to obtain a plot of tuning parameter values against cross-validation error. Save the result as `ridge_best_lambdas_1e`. The arrays of cross-validation errors and their standard errors are saved inside `ridge_cv_out_1c`. Choose them correctly when calling `elnet_cvplot_1d` and make sure that your cross-validation errors are positive numbers.\n",
    "\n",
    "Lastly, judging from the regularization path from Task 1b, how much are the learned model coefficients shrunk to zero relative to a linear regression model without regularization? Save your answer as string variable `regularization_amount_1e`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd3fa4-51ed-49c5-a011-56f65e3bf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_best_lambdas_1e = elnet_cvplot_1d(??)\n",
    "\n",
    "regularization_amount_1e = \"??\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8682598-916c-4a7b-b8a8-797dca3aa46c",
   "metadata": {},
   "source": [
    "### Task 1f) \n",
    "Now, we want to get test set predictions for ridge regression with tuned regularization parameter. To arrive there, do the following:\n",
    "\n",
    "1. Fit ridge regression with your personal favorite among the minimum-MSE or one-S.E. tuning parameter values. This merely requires you to specifiy a modified version of `ridge_pipe_1c` and to apply the `fit()`-method to the resulting pipeline. Save the learned model as `ridge_fit_1f`.\n",
    "2. Apply the `predict()` method to `ridge_fit_1f` in order to get output predictions for all data points in `X_test_1a`. Save them as `yhat_test_ridge_1f`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57514f3c-9e7b-4606-adc5-02bec04feec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "ridge_fit_1f  = Pipeline(??).fit(??)\n",
    "# 2.\n",
    "yhat_test_ridge_1e  = ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d590ef3a-4232-46d6-afe4-a1af9f533f2c",
   "metadata": {},
   "source": [
    "## Part 2: Lasso with scikit-learn\n",
    "\n",
    "In this slightly more difficult section, we are going to repeat Part 1 for the lasso and improvise a little with the model specification.\n",
    "\n",
    "\n",
    "### Task 2a)\n",
    "\n",
    "Repeat Tasks 1c, 1e and 1f, albeit for the lasso instead of ridge regression. That is, do the following:\n",
    "\n",
    "1. Specify a pipeline for the lasso. Save as `lasso_pipe_2a`\n",
    "2. Turn the provided array of tuning parameter candidates `lambdas_2a` into a tuning grid that works with `lasso_pipe_2a`. Save as `tune_grid_2a`\n",
    "3. Conduct cross-validation. You can reuse the splitter `cv_splits_1c`. Save as `lasso_tune_2a`.\n",
    "4. Extract detailed cross-validation results into `lasso_cv_out_2a`.\n",
    "5. Call `elnet_cvplot_1d` and save results as `lasso_best_lambdas_1e`. Decide whether minimum-MSE or one-S.E. choice is most suitable and explain shortly in the string variable `bestlambda_lasso_2a`.\n",
    "6. Set up a pipeline for Lasso with your optimal regularization parameter and learn this model in the training data. Save as `lasso_fit_2a`.\n",
    "7. Obtain test data predictions `yhat_test_lasso_2a`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2eb96-4e9f-4ab6-9b3b-62f7ddd2d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (ElasticNet, Lasso)\n",
    "\n",
    "\n",
    "# 1.\n",
    "lasso_pipe_2a = ??\n",
    "\n",
    "# 2.\n",
    "lambdas_2a = 10**np.linspace(2,-3)\n",
    "tune_grid_2a = ??\n",
    "\n",
    "# 3.\n",
    "lasso_tune_2a   = ??\n",
    "??\n",
    "\n",
    "# 4.\n",
    "lasso_cv_out_2a  = ??\n",
    "\n",
    "# 5. \n",
    "lasso_best_lambdas_2a  = ??\n",
    "\n",
    "# 6. \n",
    "lasso_fit_2a = ??\n",
    "bestlambda_lasso_2a = \"??\"\n",
    "\n",
    "# 7.\n",
    "yhat_test_lasso_2a =??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae830fc0-cf1f-4e50-a6a9-40f546f7c563",
   "metadata": {},
   "source": [
    "### Task 2b)\n",
    "\n",
    "The performance of regularized linear regression models crucially depends on which input variables we use. We already exploited this fact by adding interactions between any two variables in `X_train_1a` to our model inputs. Now, we additionally use the principal components of the original data and therefore create a hybrid between regularization and dimension reduction. \n",
    "\n",
    "Our key tool in `sklearn` for this task is be the `FeatureUnion()` function. It is specified like a pipeline, but it does not *sequentially* apply the transformations that it consists of. Instead `FeatureUnion()` executes the transformations in parallel and combines their output. \n",
    "\n",
    "Now conduct the following steps:\n",
    "\n",
    "1. Create a pipeline `pca_pipe_2b` which obtains all principal components of the data it is fit on. In addition to conducting PCA, the pipeline should standardize the data before **and** after getting principal components. `pca_pipe_2b` is a pipeline for pure variable transformation, just as `X_transform_pipe_1b` in Task 1b was.\n",
    "2. Use the `FeatureUnion()` to combine the pipelines `X_transform_pipe_1b` and `pca_pipe_2b` and save the resulting specification as `combined_transform_2b`.\n",
    "3. Write a pipeline that conducts the data transformation `combined_transform_2b` and which subsequently trains a lasso model. Save this pipeline as `lasso_pipe_2b`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361605f4-ddb3-44f2-875b-71ef91f0860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# 1.\n",
    "pca_pipe_2b = ??\n",
    "\n",
    "# 2.\n",
    "combined_transform_2b = FeatureUnion(??)\n",
    "\n",
    "# 3.\n",
    "lasso_pipe_2b = ??\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c84fb-a543-442e-b9c2-1f0b2313e83e",
   "metadata": {},
   "source": [
    "### Task 2c)\n",
    "Run 5-fold cross-validation as in Task 2a when you created the object `lasso_tune_2a`. However, use your new pipeline `lasso_pipe_2b` as estimator. Save the resulting object as `lasso_tune_2c`. \n",
    "\n",
    "Then, let's skip the process of looking at the curve of cross-validation errors and of deciding between minimum MSE and one-S.E. tuning parameter values. Once fitted, an object created with `GridSearchCV()` allows you to directly get predictions from the model with tuning parameter that minimizes cross-validation error. You only need to apply the `predict()` method to this object. Do this now in order to get output predictions for the test inputs `X_test_1a`. Save your predictions as `yhat_test_lasso_2c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe5052-8f4a-44e4-96db-145fc6271dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_tune_2b = ??\n",
    "??\n",
    "yhat_test_lasso_2b = ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36527c4d-d3d5-4c16-b80f-c9b2b71d28c4",
   "metadata": {},
   "source": [
    "### Task 2d \n",
    "Lasso performs variable selection in addition to shrinkage. For this reason, we move outside our prediction-centered machine learning bubble for a second and have a look at the input variables that are included in our chosen lasso model from Task 2c. \n",
    "\n",
    "The model with best tuning parameter is saved as an attribute in `lasso_tune_2b`. Look up in the [GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) which attribute that is and save it as an object `lasso_fit_2d`.\n",
    "\n",
    "The learned coefficients of the lasso model are saved as an attribute inside `lasso_fit_2d`. Look up the documentation for [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) or [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) (depending on which function you used) to identify the correct attribute. Then, note that your estimator is an entire pipeline. For that reason, address the last step of this pipeline (by name) and save the attribute which contains its learned coefficients as a new object `lasso_coefs_2d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09693d-cefc-4a0f-ab58-d9a71b2c3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_fit_2d = ??\n",
    "\n",
    "lasso_coefs_2d = ??\n",
    "\n",
    "# Run the four lines below to match variable names with coefficient values.\n",
    "poly_feature_names  = X_transform_pipe_1b['poly2'].get_feature_names_out(input_features=X_train_1a.columns)\n",
    "pca_component_names = [f'PC{idx}' for idx in range(1, X_train_1a.shape[1] + 1)]\n",
    "all_feature_names   = np.concatenate([poly_feature_names, pca_component_names])\n",
    "lasso_coefs_2d      = pd.DataFrame({'Variable': all_feature_names, 'Coefficient': lasso_coefs_2d})\n",
    "print(lasso_coefs_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beced148-b679-426c-9215-3db6d9feb74b",
   "metadata": {},
   "source": [
    "## Part 3: Elastic net and overall performance evaluation\n",
    "\n",
    "Now that we successfully tuned both ridge regression and the lasso, doing the same for the elastic net is very simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977ffbc-b42e-48cd-9d9b-bab4c1c088c9",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "\n",
    "Conduct the following tasks to set up your cross-validation setup\n",
    "\n",
    "1. Create a pipeline with the same setup as in `ridge_pipe_1c` or `lasso_pipe_2a` except for specifying the elastic net in the last step. Save the object as `elnet_pipe_3a`.\n",
    "2.  Create a dictionary `tune_grid_3a` concerning candidate values of your two tuning parameters. The names of this dictionary should be chosen so that they work with `elnet_pipe_3a`. The candidate values for the regularization parameter can be those saved in `lambdas_2a`. For the `l1_ratio` parameter that weights l1- and l2-penalties, choose six values from 0 to 1 with equal distance to each other.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd6817-1a47-4907-b17c-36222914fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "elnet_pipe_3a = ??\n",
    "# 2.\n",
    "tune_grid_3a = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ca7ac-10b0-498d-94c4-5184d69c1e01",
   "metadata": {},
   "source": [
    "### Task 3b)\n",
    "The two objects created in Task 3a are all inputs to `GridSearchCV()` that are specific to elastic net. \n",
    "\n",
    "First, specify and fit an object `elnet_tune_3b` with `GridSearchCV()`. The criterion for predictive accuracy and the split into five folds should be the same as before.\n",
    "\n",
    "Second, look in the [GridSearchCV() documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for the attribute in `elnet_tune_3b` which contains the best tuning parameter values. Save this attribute as `tune_elnet_best_3b`. Do the chosen tuning parameter values result in a model that leans more into the direction of ridge regression or more towards the lasso? Write a well-motivated answer into the string variable `interpret_tune_3b`\n",
    "\n",
    "Third, get predictions for the test inputs `X_test_1a` from `elnet_tune_3b` (i.e. from the model that leads to minimum cross-validation error). Save them as \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f8b34-5056-4dfa-bdc6-3f11cf704b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "elnet_tune_3b = ??\n",
    "??\n",
    "\n",
    "# 2.\n",
    "tune_elnet_best_3b = ??\n",
    "interpret_tune_3b = \"??\"\n",
    "\n",
    "# 3.\n",
    "yhat_test_elnet_3b = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b48f14-f92c-40f3-be7e-32c5c539ab17",
   "metadata": {},
   "source": [
    "### Task 3c) \n",
    "\n",
    "We have now obtained predictions on test data for four different versions of the elastic net. It is time to find out which of them performs best. Use the observed test outcomes `y_test_1a` to calculate the mean squared error for all `yhat_test`-objects that we have created so far. You can calculate MSE manually or use the `mean_squared_error` function in the metrics module of `sklearn`. Save them as `MSE_` plus the name of the method that we used previously.\n",
    "\n",
    "Which one among the four candidate algorithms is superior? Write your conclusion and some details about the margin between the best and the remaining algorithms in the string variable `conclusion_3c` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365979f-9ef5-4989-a1f0-4c7d9203b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE_ridge   = ??\n",
    "MSE_lasso_a = ??\n",
    "MSE_lasso_b = ??\n",
    "MSE_elnet   = ??\n",
    "\n",
    "conclusion_3c = \"??\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c68a4f-0b16-45cf-965b-7a965892683c",
   "metadata": {},
   "source": [
    "## Part 4: Manual cross-validation for ridge regression\n",
    "\n",
    "In this really advanced part, we are going to manually conduct the grid search over tuning parameter values that `GridSearchCV()` automatically provides us with. We are going to find the optimal tuning parameter for ridge regression. The learning goal of this part is to realize what a gigantic mess machine learning life is without `sklearn` (or similar libraries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957ed6f-51e1-4bd9-9be4-552149639db7",
   "metadata": {},
   "source": [
    "### Task 4a)\n",
    "Write a function `ridge_testMSE_4a` that takes the following inputs:\n",
    "\n",
    "- `Xtrain`: training inputs\n",
    "- `ytrain`: training output\n",
    "- `Xtest`:  test inputs\n",
    "- `ytest`:  test outputs\n",
    "- `lam`:    tuning parameter value\n",
    "\n",
    "The function is supposed to do the following: \n",
    "1. Set the current tuning parameter value `lam` as the `alpha`-argument of your ridge regression estimator in `ridge_pipe_1c`. The `set_params()`-method allows you to do this. The name of the `alpha` argument must be specified as `xyz__alpha` where you **replace xyz** with the name that you gave the ridge regression step in `ridge_pipe_1c`.\n",
    "2. Fit the pipeline `ridge_pipe_1c` from Part 1 on the training data. Specify the current tuning parameter value `lam` as an additional argument to the fit-method. \n",
    "3. Use the fitted model to predict outputs for the test inputs.\n",
    "4. Calculate the MSE and return it as function output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dd467-39d6-4994-bdab-5e18e2444166",
   "metadata": {},
   "outputs": [],
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3501e-9f2b-4806-a81d-a62c37cef8fa",
   "metadata": {},
   "source": [
    "### Task 4b)\n",
    "Write a function `ridge_testMSE_grid_4b` that takes the same inputs as `ridge_testMSE_4a` except that it takes an entire array of tuning parameter values `lam_grid` instead of one value `lam`. For each value in `lam_grid` it gets test MSE from `ridge_testMSE_4a`. The entire NumPy array of test MSEs is then returned as function output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9cd0f-24ea-4dfb-8a22-c8bc5d4edbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdca098-31cd-4515-ad58-37039eec86ff",
   "metadata": {},
   "source": [
    "### Task 4c)\n",
    "\n",
    "Write a function `ridge_kfolderr_4c` that takes the following inputs:\n",
    "\n",
    "- `X`: a matrix of model inputs,\n",
    "- `y`: a vector of model outputs,\n",
    "- `lamgrid:`a vector of tuning parameter values,\n",
    "- `batchid`: A vector that specifies to which batch a particular data point belongs to.\n",
    "\n",
    "`ridge_kfolderr_4c` should first identify $K$ as the maximum value in `batchid`. Then it should loop over the values $1,2,\\ldots,K$. At iteration $k$, the loop should do the following:\n",
    "\n",
    "1. Set `X_train` (`y_train`) as all data points in `X` (`y`) that do *not* belong to batch $k$,\n",
    "2. Set `X_test` (`y_test`) as all data points in `X` (`y`) that *belong* to batch $k$.\n",
    "3. Call `ridge_testMSE_grid_4c` for the given split into training and test batches to get test MSEs for the entire vector `lamgrid`.\n",
    "\n",
    "Once the loop has finished, the test MSEs of all $K$ iterations should be averaged. The resulting vector of k-fold cross-validation errors should be the function output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5720e56-dd39-4793-bcaa-1a4680487917",
   "metadata": {},
   "outputs": [],
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca691d2-d9a4-48e7-aff9-e3f0ee2d7fef",
   "metadata": {},
   "source": [
    "### Task 4d)\n",
    "\n",
    "Below, I specify `lamgrid_4d`, a grid of potential values for $\\lambda$, as well as `batches_4d`, an allocation of data points to batches. Do the following: \n",
    "\n",
    "1. Use `ridge_kfolderr_4c` with these inputs as well as `y_train_1a` and `X_train_1a` to get k-fold CV errors for every tuning parameter value in `lamgrid_4d`. Save this object as `kfolderrs_4d`,\n",
    "2. Use `which.min()` to extract the index of the smallest k-fold CV value in `kfolderrs_4d` into a new object `minindex_4d`,\n",
    "3. Save the k-fold CV error at index `minindex_4d` of `lamgrid_4d` as `best_lambda_4d`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0745f16-6557-4f32-9b3b-c6551c4315ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
